{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes by Backprop: Mushroom Contextual Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Background - Multi-armed and Contextual Bandit problems:__ <br>\n",
    "_“Bandit”_ in _“multi-armed bandits”_ comes from _“one-armed bandit”_ machines used in a casino. Imagine that you are in a casino with many one-armed bandit machines. Each machine has a different probability of a win. Your goal is to maximize total payout. You can pull a limited number of arms, and you don’t know which bandit to use to get the best payout. The problem involves exploration/exploitation tradeoff: you should balance between trying different bandits to learn more about an expected payout of every machine, but you also want to exploit the best bandit you know about more. While multi-armed bandits select the strategy which maximises the expected reward without taking into consideration the state of the environment, _contextual bandits_ output an action based on the context.\n",
    "\n",
    "__Mushroom Case Stuty:__ <br>\n",
    "We are provided with a list of 8124 mushrooms, each having 22 features (characteristcs of the mushroom) and 1 label (poisonous or edible). Our agent can carry out 2 actions: eat a mushroom or not eat a mushroom. The problem context is the vector of features which is associated with the mushroom which the agent is about to eat/non eat.\n",
    "If our agent eats an edible mushroom, it receives a reward of 5. If the agent eats a poisonous mushroom, it receives a reward of -35 with 0.5 probability and a reward of 5 with 0.5 probaility. If the agent doesn't eat, it receives a reward o 0.\n",
    "\n",
    "We are also provided an _oracle_. The oracle always selects the right action, receiving a reward of 5 when it eats an edible mushroom, and a reward of 0 when it doesn't eat.\n",
    "\n",
    "__Objective:__ <br>\n",
    "Create a BNN which minimises the _cumulative regret_ of the agent. Regreat measures the difference between the oracle and our agent's reward.\n",
    "\n",
    "__BNN Architecture:__\n",
    "- 2 hidden layers\n",
    "- Each layer has 100 rectified units\n",
    "- Vector input: vector consisting of the mushroom features (context) and a one of _K_ encoding of the action\n",
    "- Output: single scalar representing the expected reward of the given action in the given context\n",
    "\n",
    "__Additional Important Information:__\n",
    "- To calculate the expected reward for an action, Google samples twice the weights and averages the outputs\n",
    "- To train the network, Google keeps a buffer of 4096 mushrooms.\n",
    "- For training, Google randomly draws minibatches of size 64 for 64 training steps.\n",
    "- After every training stage, the agent interacts with a new mushroom\n",
    "\n",
    "## TASKS:\n",
    "- Data preparation: DONE\n",
    "- Reward function: DONE\n",
    "- Initialise buffer function: DONE\n",
    "- Update buffer function: DONE\n",
    "- Create class for Gaussian distribution: DONE\n",
    "- Create class for generating prior distribution: DONE\n",
    "- Create class for generating BNN layer: DONE\n",
    "- Create BNN: Need to change\n",
    "- Create function for creating network estimates: TO BE DONE\n",
    "- Create function for updating network parameters: TO BE DONE\n",
    "\n",
    "\n",
    "### Algorithm for network estimtes:\n",
    "##### Inputs: network and mushroom - Returns rewards for both actions\n",
    "def network-estimates(network, mushroom): <br>\n",
    "    sample w1,w2<br>\n",
    "    r1 = 0.5 * (f(mushroom,eat, w1) + f(mushroom,don't eat, w1))<br>\n",
    "    r2 = 0.5 * (f(mushroom,eat, w2) + f(mushroom,don't eat, w2))<br>\n",
    "    return r1,r2<br>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Data Preparation:__ ## \n",
    "Input is the data file. Output is an array of one-hot encoded labels (y, shape: 8124) and an array of context features (x, shape: 8124 elements, each with 117 features). 117 features derive from doing a one-hot encoding on the feature classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorcandelaney/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/lorcandelaney/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:380: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. The passed value of 'all' is the default and can simply be removed.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import data from file\n",
    "df = pd.read_csv(os.getcwd() + '/agaricus-lepiota.data', sep=',', header=None,\n",
    "             error_bad_lines=False, warn_bad_lines=True, low_memory=False)\n",
    "\n",
    "# Set pandas to output all of the columns in output\n",
    "df.columns = ['class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment',\n",
    "         'gill-spacing','gill-size','gill-color','stalk-shape','stalk-root',\n",
    "         'stalk-surf-above-ring','stalk-surf-below-ring','stalk-color-above-ring','stalk-color-below-ring',\n",
    "         'veil-type','veil-color','ring-number','ring-type','spore-color','population','habitat']\n",
    "\n",
    "# Split context from label\n",
    "X = pd.DataFrame(df, columns=df.columns[1:len(df.columns)], index=df.index)\n",
    "# Put the class values (0th column) into Y\n",
    "Y = df['class']\n",
    "\n",
    "# Transform labels into one-hot encoded array\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "y = le.transform(Y)\n",
    "\n",
    "# Temporary variable to avoid error \n",
    "x_tmp = pd.DataFrame(X,columns=[X.columns[0]])\n",
    "\n",
    "# Encode each feature column and add it to x_train \n",
    "for colname in X.columns:\n",
    "    le.fit(X[colname])\n",
    "    #print(colname, le.classes_)\n",
    "    x_tmp[colname] = le.transform(X[colname])\n",
    "\n",
    "# Produce mushroom array: 8124 mushrooms, each with 117 one-hot encoded features\n",
    "oh = preprocessing.OneHotEncoder(categorical_features='all')\n",
    "oh.fit(x_tmp)\n",
    "x = oh.transform(x_tmp).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Reward function:__ ##\n",
    "Implemented as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REWARD FUNCTION\n",
    "\n",
    "def reward_function(action_chosen, label):\n",
    "    # REWARDS FOR AGENT\n",
    "    #  Eat poisonous mushroom\n",
    "    if action_chosen == 0 and label == 1:\n",
    "        if np.random.rand() > 0.5:\n",
    "            reward = -35\n",
    "        else:\n",
    "            reward = 5\n",
    "    #  Eat edible mushroom\n",
    "    elif action_chosen == 0 and label == 0:\n",
    "        reward = 5\n",
    "    # Do not eat nay mushroom\n",
    "    else:\n",
    "        reward = 0\n",
    "    \n",
    "    # REWARD FOR ORACLE\n",
    "    if label == 1:\n",
    "        oracle_reward = 0\n",
    "    else:\n",
    "        oracle_reward = 5\n",
    "    return reward, oracle_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mushroom Buffer\n",
    "Generate buffer to keep 4096 elements used to train the Bayesian Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Buffer: an array of arrays. Each array contains the context of a mushroom, a randomly \n",
    "# selected action for the mushroom and the respective reward obtained when taking the action\n",
    "\n",
    "\n",
    "def init_buffer():\n",
    "\n",
    "    init_buffer = []\n",
    "\n",
    "    for i in range(4096):\n",
    "        \n",
    "        # Generate random action\n",
    "        init_action = random.randint(0,1)\n",
    "\n",
    "        # Calculate the expected reward by calling the reward_function. The inputs of the reward function are \n",
    "        # the action and the label of the mushroom (edible/poisonous). Returns expected reward for agent and for the oracle\n",
    "        init_rewards = reward_function(init_action, y[i])\n",
    "\n",
    "        # We take only the reward for the action since we include only this in the buffer\n",
    "        init_agent_rewards = init_rewards[0]\n",
    "\n",
    "        # Create one element of the buffer and append it to the buffer array. Each element of the buffer is an array \n",
    "        # which includes the expected reward, the action taken and the mushroom context\n",
    "        buffer_element = [init_agent_rewards, init_action]\n",
    "        element = np.concatenate((buffer_element, x[i]))\n",
    "        buffer.append(element)\n",
    "    \n",
    "    return init_buffer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method for uopdating the buffer after each training stage.\n",
    "# Inputs: current state of the buffer, the action taken on the previous mushroom, the obtained reward and the context\n",
    "# Outputs: pop the last element in the buffer, append the element formed with the inputs and return the updated buffer\n",
    "\n",
    "def buffer_update(buffer, mushroom, action, reward, context):\n",
    "    \n",
    "    element = [reward, action]\n",
    "    new_buffer_element = np.concatenate((element, context))\n",
    "    buffer.pop()\n",
    "    buffer.append(new_element)\n",
    "\n",
    "    return buffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available?:  False\n"
     ]
    }
   ],
   "source": [
    "# Define some hyperparameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "print(\"Cuda available?: \",torch.cuda.is_available())\n",
    "\n",
    "PI = 0.5\n",
    "SIGMA_1 = torch.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.FloatTensor([math.exp(-6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create class for Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taken from source\n",
    "\n",
    "class Gaussian(object):\n",
    "    def __init__(self, mu, rho):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.rho = rho\n",
    "        self.normal = torch.distributions.Normal(0,1)\n",
    "    \n",
    "    @property\n",
    "    def sigma(self):\n",
    "        return torch.log1p(torch.exp(self.rho))\n",
    "    \n",
    "    def sample(self):\n",
    "        epsilon = self.normal.sample(self.rho.size()).to(DEVICE)\n",
    "        return self.mu + self.sigma * epsilon\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        return (-math.log(math.sqrt(2 * math.pi))\n",
    "                - torch.log(self.sigma)\n",
    "                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create class for generating mixed gaussian prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taken from source\n",
    "\n",
    "class ScaleMixtureGaussian(object):\n",
    "    def __init__(self, pi, sigma1, sigma2):\n",
    "        super().__init__()\n",
    "        self.pi = pi\n",
    "        self.sigma1 = sigma1\n",
    "        self.sigma2 = sigma2\n",
    "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
    "        self.gaussian2 = torch.distributions.Normal(0,sigma2)\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
    "        prob2 = torch.exp(self.gaussian2.log_prob(input))\n",
    "        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create class for generating BNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taken from source\n",
    "\n",
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        # Weight parameters\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5,-4))\n",
    "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
    "        # Bias parameters\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))\n",
    "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
    "        # Prior distributions\n",
    "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.log_prior = 0\n",
    "        self.log_variational_posterior = 0\n",
    "\n",
    "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
    "        if self.training or sample:\n",
    "            weight = self.weight.sample()\n",
    "            bias = self.bias.sample()\n",
    "        else:\n",
    "            weight = self.weight.mu\n",
    "            bias = self.bias.mu\n",
    "        if self.training or calculate_log_probs:\n",
    "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
    "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
    "        else:\n",
    "            self.log_prior, self.log_variational_posterior = 0, 0\n",
    "\n",
    "        return F.linear(input, weight, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate BNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To be changed\n",
    "\n",
    "class BayesianNetwork(nn.Module):\n",
    "    def __init__(self, inputSize, CLASSES, layers, activations, SAMPLES, BATCH_SIZE, NUM_BATCHES):\n",
    "        super().__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.activations = activations\n",
    "        self.CLASSES = CLASSES\n",
    "        self.SAMPLES = SAMPLES\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.NUM_BATCHES = NUM_BATCHES\n",
    "        self.DEPTH = 0\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        if layers.size == 0:\n",
    "            self.layers.append(BayesianLinear(inputSize, CLASSES))\n",
    "            self.DEPTH += 1\n",
    "        else:\n",
    "            self.layers.append(BayesianLinear(inputSize, layers[0]))\n",
    "            self.DEPTH += 1\n",
    "            for i in range(layers.size-1):\n",
    "                self.layers.append(BayesianLinear(layers[i], layers[i+1]))\n",
    "                self.DEPTH += 1\n",
    "            self.layers.append(BayesianLinear(layers[layers.size-1], CLASSES))\n",
    "            self.DEPTH += 1\n",
    "            \n",
    "    def forward(self, x, sample=False):\n",
    "        x = x.view(-1, self.inputSize)\n",
    "        layerNumber = 0\n",
    "        for i in range(self.activations.size):\n",
    "            if self.activations[i]=='relu':\n",
    "                x = F.relu(self.layers[layerNumber](x, sample))\n",
    "            elif self.activations[i]=='softmax':\n",
    "                x = F.log_softmax(self.layers[layerNumber](x, sample), dim=1)\n",
    "            else:\n",
    "                x = self.layers[layerNumber](x, sample)\n",
    "            layerNumber+= 1\n",
    "        return x\n",
    "    \n",
    "    def log_prior(self):\n",
    "        value = 0\n",
    "        for i in range(self.DEPTH):\n",
    "            value+= self.layers[i].log_prior\n",
    "        return value\n",
    "    \n",
    "    def log_variational_posterior(self):\n",
    "        value = 0\n",
    "        for i in range(self.DEPTH):\n",
    "            value+= self.layers[i].log_variational_posterior\n",
    "        return value\n",
    "    \n",
    "    def sample_elbo(self, input, target):\n",
    "        samples=self.SAMPLES\n",
    "        outputs = torch.zeros(samples, self.BATCH_SIZE, self.CLASSES).to(DEVICE)\n",
    "        log_priors = torch.zeros(samples).to(DEVICE)\n",
    "        log_variational_posteriors = torch.zeros(samples).to(DEVICE)\n",
    "        negative_log_likelihood = torch.zeros(samples).to(DEVICE)\n",
    "        \n",
    "        for i in range(samples):\n",
    "            outputs[i] = self.forward(input, sample=True)\n",
    "            log_priors[i] = self.log_prior()\n",
    "            log_variational_posteriors[i] = self.log_variational_posterior()\n",
    "            if self.CLASSES == 1:\n",
    "                negative_log_likelihood[i] = (.5 * (target - outputs[i]) ** 2).sum()\n",
    "            \n",
    "        log_prior = log_priors.mean()\n",
    "        log_variational_posterior = log_variational_posteriors.mean()\n",
    "        if self.CLASSES > 1:\n",
    "            negative_log_likelihood = F.nll_loss(outputs.mean(0), target, size_average=False)\n",
    "        else:\n",
    "            negative_log_likelihood = negative_log_likelihood.mean()\n",
    "        loss = (log_variational_posterior - log_prior)/self.NUM_BATCHES + negative_log_likelihood\n",
    "        return loss, log_prior, log_variational_posterior, negative_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
