{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../BayesCNN/')\n",
    "from utils import DEVICE\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running for 10000 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/preprocessing/_encoders.py:375: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. The passed value of 'all' is the default and can simply be removed.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#### CUDA NOT YET IMPLEMENTED - DISABLE IN BayesBackpropagation.py ###\n",
    "\n",
    "NB_STEPS = 10000\n",
    "print('running for {0} steps'.format(NB_STEPS))\n",
    "\n",
    "# Import data from file\n",
    "df = pd.read_csv(os.getcwd() + '/Pytorch/agaricus-lepiota.data', sep=',', header=None,\n",
    "             error_bad_lines=False, warn_bad_lines=True, low_memory=False)\n",
    "\n",
    "# Set pandas to output all of the columns in output\n",
    "df.columns = ['class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment',\n",
    "         'gill-spacing','gill-size','gill-color','stalk-shape','stalk-root',\n",
    "         'stalk-surf-above-ring','stalk-surf-below-ring','stalk-color-above-ring','stalk-color-below-ring',\n",
    "         'veil-type','veil-color','ring-number','ring-type','spore-color','population','habitat']\n",
    "\n",
    "# Split context from label\n",
    "X = pd.DataFrame(df, columns=df.columns[1:len(df.columns)], index=df.index)\n",
    "# Put the class values (0th column) into Y\n",
    "Y = df['class']\n",
    "\n",
    "# Transform labels into one-hot encoded array\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "y = le.transform(Y)\n",
    "\n",
    "# Temporary variable to avoid error \n",
    "x_tmp = pd.DataFrame(X,columns=[X.columns[0]])\n",
    "\n",
    "# Encode each feature column and add it to x_train \n",
    "for colname in X.columns:\n",
    "    le.fit(X[colname])\n",
    "    #print(colname, le.classes_)\n",
    "    x_tmp[colname] = le.transform(X[colname])\n",
    "\n",
    "# Produce mushroom array: 8124 mushrooms, each with 117 one-hot encoded features\n",
    "oh = preprocessing.OneHotEncoder(categorical_features='all')\n",
    "oh.fit(x_tmp)\n",
    "x = oh.transform(x_tmp).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(eaten, edible):\n",
    "    # REWARDS FOR AGENT\n",
    "    #  Eat poisonous mushroom\n",
    "    if not eaten:\n",
    "        return 0\n",
    "    if eaten and edible:\n",
    "        return 5\n",
    "    elif eaten and not edible:\n",
    "        return 5 if np.random.rand() > 0.5 else -35\n",
    "\n",
    "def oracle_reward(edible):\n",
    "    return 5*edible    \n",
    "\n",
    "def init_buffer():\n",
    "    bufferX, bufferY = [], []\n",
    "    for i in np.random.choice(range(len(x)), 4096):\n",
    "        eat = np.random.rand()>0.5\n",
    "        bufferX.append(np.concatenate((x[i], [1, 0] if eat else [0, 1])))\n",
    "        bufferY.append(get_reward(eat, y[i]))\n",
    "    return bufferX, bufferY\n",
    "\n",
    "# Define some hyperparameters\n",
    "\n",
    "Var = lambda x, dtype=torch.FloatTensor: Variable(\n",
    "    torch.from_numpy(x).type(dtype)).to(DEVICE)\n",
    "\n",
    "bufferX, bufferY = init_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MushroomNet():\n",
    "    def __init__(self, label = 'MushNet', n_weight_sampling=2):\n",
    "        self.label = label\n",
    "        self.n_weight_sampling = n_weight_sampling\n",
    "        self.epsilon = 0\n",
    "        self.net = None\n",
    "        self.loss, self.optimizer = None, None\n",
    "        self.cum_regrets = [0]\n",
    "        self.bufferX = np.copy(bufferX)\n",
    "        self.bufferY = np.copy(bufferY)\n",
    "    \n",
    "    # Use NN to decide next action\n",
    "    def try_ (self, mushroom):\n",
    "        samples = self.n_weight_sampling\n",
    "        context, edible = x[mushroom], y[mushroom]\n",
    "        try_eat = Var(np.concatenate((context, [1, 0])))\n",
    "        try_reject = Var(np.concatenate((context, [0, 1])))\n",
    "        \n",
    "        # Calculate rewards using model\n",
    "        with torch.no_grad():\n",
    "            r_eat = sum([self.net(try_eat) for _ in range(samples)]).item()/samples\n",
    "            r_reject = sum([self.net(try_reject) for _ in range(samples)]).item()/samples\n",
    "        \n",
    "        # Take random action for epsilon greedy agents, calculate agent's reward\n",
    "        eaten = r_eat > r_reject\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            eaten = (np.random.rand()<.5)\n",
    "        agent_reward = get_reward(eaten, edible)\n",
    "        \n",
    "        # Get rewards and update buffer\n",
    "        if eaten:\n",
    "            action = [1, 0]\n",
    "        else:\n",
    "            action = [0, 1]\n",
    "        bufferX.append(np.concatenate((context, action)))\n",
    "        bufferY.append(agent_reward)\n",
    "        \n",
    "        # Calculate regret\n",
    "        oracle = oracle_reward(edible)\n",
    "        regret = oracle - agent_reward\n",
    "        self.cum_regrets.append(self.cum_regrets[-1]+regret)\n",
    "        return regret\n",
    "\n",
    "    # Feed next mushroom\n",
    "    def update(self, mushroom):\n",
    "        rg = self.try_(mushroom)\n",
    "        bX = Var(np.array(self.bufferX[-4096:]))\n",
    "        bY = Var(np.array(self.bufferY[-4096:]))\n",
    "        for idx in np.split(np.random.permutation(range(4096)), 64):\n",
    "            self.loss_step(bX[idx], bY[idx])\n",
    "        return rg\n",
    "    \n",
    "    def loss_step(self, x, y):\n",
    "        raise NotImplementedError\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for BBB agent\n",
    "from bayes import BayesWrapper\n",
    "from utils import prior_nll\n",
    "\n",
    "mlp = lambda inputs:nn.Sequential(\n",
    "        nn.Linear(inputs, 100), nn.ReLU(),\n",
    "        nn.Linear(100, 100), nn.ReLU(),\n",
    "        nn.Linear(100, 1)).to(DEVICE)\n",
    "\n",
    "class BBB_MNet(MushroomNet):\n",
    "    def __init__(self, label):\n",
    "        super().__init__(label)\n",
    "        self.net = BayesWrapper(name='BayesMush',\n",
    "                               net = mlp(x.shape[1]+2),\n",
    "                               prior_nll=prior_nll,\n",
    "                               type='regression')\n",
    "\n",
    "    def loss_step(self, x, y, n_samples = 2):\n",
    "        outputs = [self.net(x)[:,0] for _ in range(n_samples)]\n",
    "        self.net.step(outputs, y, 1/64)\n",
    "\n",
    "\n",
    "# Class for Greedy agents\n",
    "class EpsGreedyMlp(MushroomNet):\n",
    "    def __init__(self, epsilon=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_weight_sampling = 1\n",
    "        self.epsilon = epsilon\n",
    "        self.net = mlp(x.shape[1]+2)\n",
    "        self.bufferX, self.bufferY = init_buffer()\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr = 0.001)\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def loss_step(self, x, y):\n",
    "        self.net.zero_grad()\n",
    "        loss = self.mse(self.net.forward(x), y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1555/2000 BBB : 3190, Greedy: 1835"
     ]
    }
   ],
   "source": [
    "NB_STEPS = 2000\n",
    "\n",
    "mushroom_nets = {'bbb':BBB_MNet(label = 'BBB'),\n",
    "    'e0':EpsGreedyMlp(epsilon=0, label = 'Greedy')}\n",
    "\n",
    "\n",
    "for step in range(NB_STEPS):\n",
    "    mushroom = np.random.randint(len(x))\n",
    "    for j, (key, net) in enumerate(mushroom_nets.items()):\n",
    "        net.update(mushroom)\n",
    "    print('\\r Step {2}/{3} BBB : {0}, Greedy: {1}'.format(\n",
    "        mushroom_nets['bbb'].cum_regrets[-1],\n",
    "        mushroom_nets['e0'].cum_regrets[-1], step+1, NB_STEPS), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict({net.label: net.cum_regrets for i, net in mushroom_nets.items()})\n",
    "df.to_csv('mushroom_regrets_bbb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1100: \n",
    "me : BBB= 2300, Greedy=1600\n",
    "Yours : Greedy = 2600, BBB = 800"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
