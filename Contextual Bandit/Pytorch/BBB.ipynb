{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes by Backprop: Mushroom Contextual Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Background - Multi-armed and Contextual Bandit problems:__ <br>\n",
    "_“Bandit”_ in _“multi-armed bandits”_ comes from _“one-armed bandit”_ machines used in a casino. Imagine that you are in a casino with many one-armed bandit machines. Each machine has a different probability of a win. Your goal is to maximize total payout. You can pull a limited number of arms, and you don’t know which bandit to use to get the best payout. The problem involves exploration/exploitation tradeoff: you should balance between trying different bandits to learn more about an expected payout of every machine, but you also want to exploit the best bandit you know about more. While multi-armed bandits select the strategy which maximises the expected reward without taking into consideration the state of the environment, _contextual bandits_ output an action based on the context.\n",
    "\n",
    "__Mushroom Case Stuty:__ <br>\n",
    "We are provided with a list of 8124 mushrooms, each having 22 features (characteristcs of the mushroom) and 1 label (poisonous or edible). Our agent can carry out 2 actions: eat a mushroom or not eat a mushroom. The problem context is the vector of features which is associated with the mushroom which the agent is about to eat/non eat.\n",
    "If our agent eats an edible mushroom, it receives a reward of 5. If the agent eats a poisonous mushroom, it receives a reward of -35 with 0.5 probability and a reward of 5 with 0.5 probaility. If the agent doesn't eat, it receives a reward o 0.\n",
    "\n",
    "We are also provided an _oracle_. The oracle always selects the right action, receiving a reward of 5 when it eats an edible mushroom, and a reward of 0 when it doesn't eat.\n",
    "\n",
    "__Objective:__ <br>\n",
    "Create a BNN which minimises the _cumulative regret_ of the agent. Regreat measures the difference between the oracle and our agent's reward.\n",
    "\n",
    "__BNN Architecture:__\n",
    "- 2 hidden layers\n",
    "- Each layer has 100 rectified units\n",
    "- Vector input: vector consisting of the mushroom features (context) and a one of _K_ encoding of the action\n",
    "- Output: single scalar representing the expected reward of the given action in the given context\n",
    "\n",
    "__Additional Important Information:__\n",
    "- To calculate the expected reward for an action, Google samples twice the weights and averages the outputs\n",
    "- To train the network, Google keeps a buffer of 4096 mushrooms.\n",
    "- For training, Google randomly draws minibatches of size 64 for 64 training steps.\n",
    "- After every training stage, the agent interacts with a new mushroom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from BayesBackpropagation import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Data Preparation:__ ## \n",
    "Input is the data file. Output is an array of one-hot encoded labels (y, shape: 8124) and an array of context features (x, shape: 8124 elements, each with 117 features). 117 features derive from doing a one-hot encoding on the feature classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from file\n",
    "df = pd.read_csv(os.getcwd() + '/agaricus-lepiota.data', sep=',', header=None,\n",
    "             error_bad_lines=False, warn_bad_lines=True, low_memory=False)\n",
    "\n",
    "# Set pandas to output all of the columns in output\n",
    "df.columns = ['class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment',\n",
    "         'gill-spacing','gill-size','gill-color','stalk-shape','stalk-root',\n",
    "         'stalk-surf-above-ring','stalk-surf-below-ring','stalk-color-above-ring','stalk-color-below-ring',\n",
    "         'veil-type','veil-color','ring-number','ring-type','spore-color','population','habitat']\n",
    "\n",
    "# Split context from label\n",
    "X = pd.DataFrame(df, columns=df.columns[1:len(df.columns)], index=df.index)\n",
    "# Put the class values (0th column) into Y\n",
    "Y = df['class']\n",
    "\n",
    "# Transform labels into one-hot encoded array\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "y = le.transform(Y)\n",
    "\n",
    "# Temporary variable to avoid error \n",
    "x_tmp = pd.DataFrame(X,columns=[X.columns[0]])\n",
    "\n",
    "# Encode each feature column and add it to x_train \n",
    "for colname in X.columns:\n",
    "    le.fit(X[colname])\n",
    "    x_tmp[colname] = le.transform(X[colname])\n",
    "\n",
    "# Produce mushroom array: 8124 mushrooms, each with 117 one-hot encoded features\n",
    "oh = preprocessing.OneHotEncoder(categorical_features='all')\n",
    "oh.fit(x_tmp)\n",
    "x = oh.transform(x_tmp).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Reward function:__ ##\n",
    "Implemented as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 117)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REWARD FUNCTION\n",
    "\n",
    "def get_reward(eaten, edible):\n",
    "    # REWARDS FOR AGENT\n",
    "    #  Eat poisonous mushroom\n",
    "    if not eaten:\n",
    "        return 0\n",
    "    if eaten and edible:\n",
    "        return 5\n",
    "    elif eaten and not edible:\n",
    "        return (5 if np.random.rand() > 0.5 else -35)\n",
    "\n",
    "def oracle_reward(edible):\n",
    "    return 5*edible    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mushroom Buffer\n",
    "Generate buffer to keep 4096 elements used to train the Bayesian Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available?:  False\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "LOADER_KWARGS = {}\n",
    "print(\"Cuda available?: \",torch.cuda.is_available())\n",
    "\n",
    "PI = 0.75\n",
    "SIGMA_1 = torch.FloatTensor([math.exp(-1)])\n",
    "SIGMA_2 = torch.FloatTensor([math.exp(-6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create class for Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "Var = lambda x, dtype=torch.FloatTensor: Variable(torch.from_numpy(x).type(dtype))\n",
    "\n",
    "\n",
    "class MushroomNet():\n",
    "    def __init__(self, label = 'MushNet', n_weight_sampling=2):\n",
    "        self.label = label\n",
    "        self.n_weight_sampling = n_weight_sampling\n",
    "        self.epsilon = 0\n",
    "        self.net = None\n",
    "        self.loss, self.optimizer = None, None\n",
    "        self.cum_regrets = [0]\n",
    "        self.bufferX = []\n",
    "        self.bufferY = []\n",
    "        \n",
    "    # Use NN to decide next action    \n",
    "    def try_ (self, mushroom):\n",
    "        samples = self.n_weight_sampling\n",
    "        context, edible = x[mushroom], y[mushroom]\n",
    "        try_eat = Var(np.concatenate((context, [1, 0])))\n",
    "        try_reject = Var(np.concatenate((context, [0, 1])))\n",
    "        \n",
    "        # Calculate rewards using model\n",
    "        with torch.no_grad():\n",
    "            r_eat = np.mean([self.net.forward(try_eat).numpy() for _ in range(samples)])\n",
    "            r_reject = np.mean([self.net.forward(try_reject).numpy() for _ in range(samples)])\n",
    "                         \n",
    "        # Take random action for epsilon greedy agents, calculate agent's reward\n",
    "        eaten = r_eat > r_reject\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            eaten = (np.random.rand()<.5)\n",
    "        agent_reward = get_reward(eaten, edible)\n",
    "        \n",
    "        # Get rewards and update buffer\n",
    "        if eaten:\n",
    "            action = [1, 0]\n",
    "        else:\n",
    "            action = [0, 1]\n",
    "        self.bufferX.append(np.concatenate((context, action)))\n",
    "        self.bufferY.append(agent_reward)\n",
    "    \n",
    "        # Calculate regret\n",
    "        oracle = oracle_reward(edible)\n",
    "        regret = oracle - agent_reward\n",
    "        self.cum_regrets.append(self.cum_regrets[-1]+regret) \n",
    "    \n",
    "        \n",
    "    # Function for generating a minibatch\n",
    "    def generate_minibatch(self, trainingX, trainingY):\n",
    "        bX = []\n",
    "        bY = []\n",
    "        for i in range(64):\n",
    "            random = np.random.randint(0, len(trainingX))\n",
    "            bX.append(trainingX[random])\n",
    "            bY.append(trainingY[random])\n",
    "        return bX, bY\n",
    "    \n",
    "    # Feed next mushroom\n",
    "    def update(self, mushroom):\n",
    "        self.try_(mushroom)\n",
    "        for minibatch in range(64):\n",
    "            bX, bY = self.generate_minibatch(self.bufferX[-4096:], self.bufferY[-4096:])\n",
    "            self.net.zero_grad()\n",
    "            self.loss(Var(np.asarray(bX)), Var(np.asarray(bY))).backward()\n",
    "            self.optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for BBB agent\n",
    "class BBB_MNet(MushroomNet):\n",
    "    def __init__(self, label, lr=0, **kwargs):\n",
    "        super().__init__(label, **kwargs)\n",
    "        self.net = BayesianNetwork(inputSize = x.shape[1]+2,\n",
    "                          CLASSES = 1, \n",
    "                          layers=np.array([100,100]), \n",
    "                          activations = np.array(['relu','relu','none']), \n",
    "                          SAMPLES = 2, \n",
    "                          BATCH_SIZE = 64,\n",
    "                          NUM_BATCHES = 64,\n",
    "                          hasScalarMixturePrior=True,\n",
    "                          PI=PI,\n",
    "                          SIGMA_1 = SIGMA_1,\n",
    "                          SIGMA_2 = SIGMA_2,\n",
    "                          GOOGLE_INIT=True,\n",
    "                          ).to(DEVICE)\n",
    "        self.lr = lr\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr = lr)\n",
    "        self.loss = lambda data, target:self.net.BBB_loss(data, target)\n",
    "        \n",
    "        \n",
    "# Class for Greedy agents\n",
    "class EpsGreedyMlp(MushroomNet):\n",
    "    def __init__(self, epsilon=0, lr=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_weight_sampling = 1\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = lr\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Linear(x.shape[1]+2, 100), nn.ReLU(),\n",
    "        nn.Linear(100, 100), nn.ReLU(),\n",
    "        nn.Linear(100, 1))\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr = lr)\n",
    "        self.mse = lambda x, y:.5*((x-y)**2).sum()\n",
    "        self.loss = lambda data, target: self.mse(self.net.forward(data), target)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_nets = {\n",
    "    \n",
    "                 '1bbb0.01':BBB_MNet(label = '1BBB 0.01', lr = 0.01),\n",
    "                 '2bbb0.01':BBB_MNet(label = '2BBB 0.01', lr = 0.01),\n",
    "    \n",
    "                 '1bbb0.001':BBB_MNet(label = '1BBB 0.001', lr = 0.001),\n",
    "                 '2bbb0.001':BBB_MNet(label = '2BBB 0.001', lr = 0.001),\n",
    "    \n",
    "                 '1bbb0.0001':BBB_MNet(label = '1BBB 0.0001', lr = 0.0001),\n",
    "                 '2bbb0.0001':BBB_MNet(label = '2BBB 0.0001', lr = 0.0001),\n",
    "    \n",
    "                 '1bbb0.00001':BBB_MNet(label = '1BBB 0.00001', lr = 0.00001),\n",
    "                 '2bbb0.00001':BBB_MNet(label = '2BBB 0.00001', lr = 0.00001)\n",
    "\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1BBB 0.01', '2BBB 0.01', '1BBB 0.001', '2BBB 0.001', '1BBB 0.0001', '2BBB 0.0001', '1BBB 0.00001', '2BBB 0.00001']\n",
      "Step 0 Regrets [0, 0, 0, 5, 0, 5, 5, 5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7fd8697da977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmushroom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmushroom_nets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmushroom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Regrets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum_regrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmushroom_nets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c51c7a4e596d>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, mushroom)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mbX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbufferX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbufferY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a8d112b0fd3e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data, target)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBBB_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Weight-Uncertainty-in-Neural-Networks/BayesBackpropagation.py\u001b[0m in \u001b[0;36mBBB_loss\u001b[0;34m(self, input, target, batch_idx)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0ms_log_pw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_log_qw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_log_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0msample_log_pw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_log_qw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lpw_lqw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Weight-Uncertainty-in-Neural-Networks/BayesBackpropagation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, infer)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Weight-Uncertainty-in-Neural-Networks/BayesBackpropagation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, infer)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Pass sampled weights and bias on to linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%capture output\n",
    "\n",
    "NB_STEPS = 50000\n",
    "\n",
    "print([net.label for lb, net in mushroom_nets.items()])\n",
    "\n",
    "for _ in range(NB_STEPS):\n",
    "    mushroom = np.random.randint(0, len(x))\n",
    "    for j, (key, net) in enumerate(mushroom_nets.items()):\n",
    "        net.update(mushroom)\n",
    "    if _ % 10 == 0 :\n",
    "        print('Step',_,'Regrets',[net.cum_regrets[-1] for lb, net in mushroom_nets.items()])\n",
    "        \n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict({net.label: net.cum_regrets for i, net in mushroom_nets.items()})\n",
    "df.to_csv('BBB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
